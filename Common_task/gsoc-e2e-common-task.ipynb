{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10956435,"sourceType":"datasetVersion","datasetId":6816080}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#resnet15=0.78\n#seresnet15=0.78,0.8\n#FFN=0.81","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T03:16:18.747327Z","iopub.execute_input":"2025-03-08T03:16:18.747606Z","iopub.status.idle":"2025-03-08T03:16:18.751083Z","shell.execute_reply.started":"2025-03-08T03:16:18.747584Z","shell.execute_reply":"2025-03-08T03:16:18.750354Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# importing necessary library\nimport h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nimport pickle\nimport timm\nfrom sklearn.metrics import roc_auc_score\n# importing torch_libraries\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import transforms\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:00:29.681741Z","iopub.execute_input":"2025-03-09T03:00:29.682063Z","iopub.status.idle":"2025-03-09T03:00:38.757358Z","shell.execute_reply.started":"2025-03-09T03:00:29.682036Z","shell.execute_reply":"2025-03-09T03:00:38.756639Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#Creating Train and Validation Dataset and DataLoader for Training of the model\nwith h5py.File(\"/kaggle/input/e2e-common-task/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\", \"r\") as f:\n    # print(\"Keys: \", list(f.keys()))\n    dataset1 = f[\"X\"]\n    dataset2 = f['y']\n    image_electron = dataset1[:]\n    label_electron= dataset2[:]\n\nwith h5py.File(\"/kaggle/input/e2e-common-task/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\", \"r\") as f:\n    # print(\"Keys: \", list(f.keys()))\n    dataset1 = f[\"X\"]\n    dataset2 = f['y']\n    image_photon = dataset1[:]\n    label_photon= dataset2[:]\n\nplt.imshow(image_electron[0][:,:,1])\nplt.axis(\"off\")  # Hide axis\nplt.show()\n\nimage_val=[]\nlabel_val=[]\nimage_train=[]\nlabel_train=[]\nfor i in range(249000):\n    if i<49800:\n        image_val.append(image_electron[i])\n        label_val.append(label_electron[i])\n        image_val.append(image_photon[i])\n        label_val.append(label_photon[i])\n    else:\n        image_train.append(image_electron[i])\n        label_train.append(label_electron[i])\n        image_train.append(image_photon[i])\n        label_train.append(label_photon[i])\n\nclass custom_dataset(Dataset):\n    def __init__(self,image_list,label_list):\n        super().__init__()\n        self.image_list=image_list\n        self.label_list=label_list\n    def __len__(self):\n        return len(self.label_list)\n    def __getitem__(self,ind):\n        image=torch.from_numpy(self.image_list[ind])\n        image=torch.permute(image,(2,0,1))[0].unsqueeze(0)\n        label=torch.tensor(self.label_list[ind],dtype=torch.float)\n        return image,label\n\nval_dataset=custom_dataset(image_val,label_val)\ntrain_dataset=custom_dataset(image_train,label_train)\n\nval_dataloader=DataLoader(val_dataset,batch_size=64,shuffle=True,num_workers=os.cpu_count())\ntrain_dataloader=DataLoader(train_dataset,batch_size=64,shuffle=True,num_workers=os.cpu_count())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:00:53.010350Z","iopub.execute_input":"2025-03-09T03:00:53.010573Z","iopub.status.idle":"2025-03-09T03:00:53.326188Z","shell.execute_reply.started":"2025-03-09T03:00:53.010554Z","shell.execute_reply":"2025-03-09T03:00:53.325460Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#RsNet15 class which imaplements models which have Parameters comparable to Resnet15\nclass ResNet15(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ResNet15, self).__init__()\n        \n        # Load ResNet-18 from timm\n        resnet18 = timm.create_model('seresnet18', pretrained=False, in_chans=1)\n        \n        # Keep initial layers\n        self.conv1 = resnet18.conv1\n        self.bn1 = resnet18.bn1\n        self.act1 = resnet18.act1  # ReLU\n        self.maxpool = resnet18.maxpool\n        \n        # Modify residual layers (removing one block each from layer3 and layer4)\n        self.layer1 = resnet18.layer1  # 2 blocks\n        self.layer2 = resnet18.layer2  # 2 blocks\n        self.layer3 = nn.Sequential(*list(resnet18.layer3.children())[:1])  # 1 block\n        self.layer4 = nn.Sequential(*list(resnet18.layer4.children())[:1])  # 1 block\n        \n        # Adaptive pooling & FC layer\n        self.global_pool = resnet18.global_pool\n        self.fc = nn.Linear(512, num_classes)  # Adjust output features\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.act1(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.global_pool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        \n        return x\n\n#Feed Forward Neural Network For experimentation\nclass ScaledFNN(nn.Module):\n    def __init__(self, input_size=32*32*1, hidden_sizes=[2048, 1024, 512, 256, 128], num_classes=1):\n        super(ScaledFNN, self).__init__()\n        \n        self.flatten = nn.Flatten()\n        self.fc_layers = nn.Sequential(\n            nn.Linear(input_size, hidden_sizes[0]),\n            nn.ReLU(),\n            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n            nn.ReLU(),\n            nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n            nn.ReLU(),\n            nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n            nn.ReLU(),\n            nn.Linear(hidden_sizes[3], hidden_sizes[4]),\n            nn.ReLU(),\n            nn.Linear(hidden_sizes[4], num_classes)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)  # Convert (32,32,1) → (1024)\n        x = self.fc_layers(x)\n        return x\n\n# Instantiate model\nmodel = ResNet15(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:01:45.899648Z","iopub.execute_input":"2025-03-09T03:01:45.899986Z","iopub.status.idle":"2025-03-09T03:01:46.086361Z","shell.execute_reply.started":"2025-03-09T03:01:45.899958Z","shell.execute_reply":"2025-03-09T03:01:46.085393Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#Define Loss and Optimizer\nmodel = pickle.load(open(\"/kaggle/working/best_model.sav\", \"rb\")).to(device)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.NAdam(model.parameters(), lr=0.000004)\n# model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:26:52.270478Z","iopub.execute_input":"2025-03-09T03:26:52.270830Z","iopub.status.idle":"2025-03-09T03:26:52.351711Z","shell.execute_reply.started":"2025-03-09T03:26:52.270802Z","shell.execute_reply":"2025-03-09T03:26:52.351076Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"num_epochs=10\nbest=10000.0\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    \n    for images, labels in tqdm(train_dataloader):\n        images, labels = images.to(device), labels.to(device).unsqueeze(-1)\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n    train_loss /= len(train_dataloader)\n\n    # Validation loop\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    pred=[]\n    label=[]\n    with torch.no_grad():\n        for images, labels in tqdm(val_dataloader):\n            images, labels = images.to(device), labels.to(device).unsqueeze(-1)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            pred.append(torch.nn.Sigmoid()(outputs).cpu().numpy())\n            label.append(labels.cpu().numpy())\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n    predictions=np.concatenate(pred)\n    label=np.concatenate(label)\n    score =  roc_auc_score(label, predictions, multi_class=\"ovr\")\n    val_loss /= len(val_dataloader)\n    val_acc = 100 * correct / (len(val_dataloader)*32)\n    if val_loss<best:\n        best=val_loss\n        pickle.dump(model, open('/kaggle/working/best_model.sav', 'wb'))\n        \n    # Print results\n    print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val roc_auc: {score:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:26:54.903367Z","iopub.execute_input":"2025-03-09T03:26:54.903657Z","iopub.status.idle":"2025-03-09T03:28:59.847996Z","shell.execute_reply.started":"2025-03-09T03:26:54.903636Z","shell.execute_reply":"2025-03-09T03:28:59.846657Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 6225/6225 [01:43<00:00, 60.37it/s]\n100%|██████████| 1557/1557 [00:10<00:00, 149.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10] | Train Loss: 0.5339 | Val Loss: 0.5410 | Val roc_auc: 0.80\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 658/6225 [00:11<01:35, 58.29it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-e46a66e55ad5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":24}]}