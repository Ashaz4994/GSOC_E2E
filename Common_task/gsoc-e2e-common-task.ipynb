{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10956435,"sourceType":"datasetVersion","datasetId":6816080}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#resnet15=0.78\n#seresnet15=0.78,0.8\n#FFN=0.81","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# importing necessary library\nimport h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nimport pickle\nimport timm\nfrom sklearn.metrics import roc_auc_score\n# importing torch_libraries\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import transforms\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Creating Train and Validation Dataset and DataLoader for Training of the model\nwith h5py.File(\"/kaggle/input/e2e-common-task/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\", \"r\") as f:\n    # print(\"Keys: \", list(f.keys()))\n    dataset1 = f[\"X\"]\n    dataset2 = f['y']\n    image_electron = dataset1[:]\n    label_electron= dataset2[:]\n\nwith h5py.File(\"/kaggle/input/e2e-common-task/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\", \"r\") as f:\n    # print(\"Keys: \", list(f.keys()))\n    dataset1 = f[\"X\"]\n    dataset2 = f['y']\n    image_photon = dataset1[:]\n    label_photon= dataset2[:]\n\nplt.imshow(image_electron[0][:,:,1])\nplt.axis(\"off\")  # Hide axis\nplt.show()\n\nimage_val=[]\nlabel_val=[]\nimage_train=[]\nlabel_train=[]\nfor i in range(249000):\n    if i<49800:\n        image_val.append(image_electron[i])\n        label_val.append(label_electron[i])\n        image_val.append(image_photon[i])\n        label_val.append(label_photon[i])\n    else:\n        image_train.append(image_electron[i])\n        label_train.append(label_electron[i])\n        image_train.append(image_photon[i])\n        label_train.append(label_photon[i])\n\nclass custom_dataset(Dataset):\n    def __init__(self,image_list,label_list):\n        super().__init__()\n        self.image_list=image_list\n        self.label_list=label_list\n    def __len__(self):\n        return len(self.label_list)\n    def __getitem__(self,ind):\n        image=torch.from_numpy(self.image_list[ind])\n        image=torch.permute(image,(2,0,1))[0].unsqueeze(0)\n        label=torch.tensor(self.label_list[ind],dtype=torch.float)\n        return image,label\n\nval_dataset=custom_dataset(image_val,label_val)\ntrain_dataset=custom_dataset(image_train,label_train)\n\nval_dataloader=DataLoader(val_dataset,batch_size=64,shuffle=True,num_workers=os.cpu_count())\ntrain_dataloader=DataLoader(train_dataset,batch_size=64,shuffle=True,num_workers=os.cpu_count())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#RsNet15 class which imaplements models which have Parameters comparable to Resnet15\nclass ResNet15(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(ResNet15, self).__init__()\n        \n        # Load ResNet-18 from timm\n        resnet18 = timm.create_model('seresnet18', pretrained=False, in_chans=1)\n        \n        # Keep initial layers\n        self.conv1 = resnet18.conv1\n        self.bn1 = resnet18.bn1\n        self.act1 = resnet18.act1  # ReLU\n        self.maxpool = resnet18.maxpool\n        \n        # Modify residual layers (removing one block each from layer3 and layer4)\n        self.layer1 = resnet18.layer1  # 2 blocks\n        self.layer2 = resnet18.layer2  # 2 blocks\n        self.layer3 = nn.Sequential(*list(resnet18.layer3.children())[:1])  # 1 block\n        self.layer4 = nn.Sequential(*list(resnet18.layer4.children())[:1])  # 1 block\n        \n        # Adaptive pooling & FC layer\n        self.global_pool = resnet18.global_pool\n        self.fc = nn.Linear(512, num_classes)  # Adjust output features\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.act1(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.global_pool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        \n        return x\n\n#Feed Forward Neural Network For experimentation\nclass ScaledFNN(nn.Module):\n    def __init__(self, input_size=32*32*1, hidden_sizes=[2048, 1024, 512, 256, 128], num_classes=1):\n        super(ScaledFNN, self).__init__()\n        \n        self.flatten = nn.Flatten()\n        self.fc_layers = nn.Sequential(\n            nn.Linear(input_size, hidden_sizes[0]),\n            nn.ReLU(),\n            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n            nn.ReLU(),\n            nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n            nn.ReLU(),\n            nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n            nn.ReLU(),\n            nn.Linear(hidden_sizes[3], hidden_sizes[4]),\n            nn.ReLU(),\n            nn.Linear(hidden_sizes[4], num_classes)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)  # Convert (32,32,1) â†’ (1024)\n        x = self.fc_layers(x)\n        return x\n\n# Instantiate model\nmodel = ResNet15(1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Define Loss and Optimizer\nmodel = pickle.load(open(\"/kaggle/working/best_model.sav\", \"rb\")).to(device)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.NAdam(model.parameters(), lr=0.000004)\n# model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs=10\nbest=10000.0\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    \n    for images, labels in tqdm(train_dataloader):\n        images, labels = images.to(device), labels.to(device).unsqueeze(-1)\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n    train_loss /= len(train_dataloader)\n\n    # Validation loop\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    pred=[]\n    label=[]\n    with torch.no_grad():\n        for images, labels in tqdm(val_dataloader):\n            images, labels = images.to(device), labels.to(device).unsqueeze(-1)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            pred.append(torch.nn.Sigmoid()(outputs).cpu().numpy())\n            label.append(labels.cpu().numpy())\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n    predictions=np.concatenate(pred)\n    label=np.concatenate(label)\n    score =  roc_auc_score(label, predictions, multi_class=\"ovr\")\n    val_loss /= len(val_dataloader)\n    val_acc = 100 * correct / (len(val_dataloader)*32)\n    if val_loss<best:\n        best=val_loss\n        pickle.dump(model, open('/kaggle/working/best_model.sav', 'wb'))\n        \n    # Print results\n    print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val roc_auc: {score:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}